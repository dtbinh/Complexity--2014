\section{ Conclusions \& Future Work }\label{sec:conc}

% To address the shortcomings mentioned in the previous section, we are
% in the process of repeating our own study with other metrics, other
% forecast methods, and time-series data from other systems.

Forecast strategies that are designed to capture predictive structure
are ineffective when signal complexity outweighs information
redundancy.  This poses a number of serious challenges in practice.
Without knowing anything about the generating process, it is difficult
to determine how much predictive structure is present in a noisy,
real-world time series.  And even if predictive structure exists, a
given forecast method may not work, simply because it cannot exploit
the structure that is present (e.g., a linear model of a nonlinear
process).  If a forecast model is not producing good results, a
practitioner needs to know why: is the reason that the data contain no
predictive structure---i.e., that no model will work---or is the model
that s/he is using simply not good enough?

In this paper, we have argued that redundancy is a useful proxy for
the inherent predictability of an empirical time series.  To
operationalize that relationship, we use an approximation of the
Kolmogorov-Sinai entropy, estimated using a weighted version of the
permutation entropy of~\cite{bandt2002per}.  This WPE technique---an
ordinal calculation of forward information transfer in a time
series---is ideal for our purposes because it works with real-valued
data and is known to converge to the true entropy value. Using a
variety of forecast models and more than 150 time-series data sets
from experiments and simulations, we have shown that prediction
accuracy is indeed correlated with weighted permutation entropy: the
higher the WPE, in general, the higher the prediction error.  The
relationship is roughly logarithmic, which makes theoretical sense,
given the nature of WPE, predictability, and MASE.

An important practical corollary to this empirical correlation of
predictability and WPE is a practical strategy for assessing
appropriateness of forecast methods.  If the forecast produced by a
particular method is poor but the time series contains a significant
amount of predictive structure, one can reasonably conclude that that
method is inadequate to the task and that one should seek another
method.  The nonlinear LMA method, for instance, performs better in
most cases because it is more general.  (This is particularly apparent
in the \col and \svdfive examples.)
% , where the other two methods do not perform well.)
The \naive ~method, which simply predicts the mean, can work very well
on noisy signals because it effects a filtering operation.  The simple
random-walk strategy outperforms LMA, \arima, and the \naive
~method on the \gcc signal, which is extremely complex---i.e.,
extremely low redundancy.
%  \naive ~wins on \svdone with the exception to the 5 outliers.

The curves and shaded regions in Figures~\ref{fig:wpe_vs_mase_best}
and~\ref{fig:wpe_vs_mase_all} generalize and operationalize the
discussion in the previous paragraph.  These geometric features are a
preliminary, but potentially useful, heuristic for knowing when a
model is not well-matched to the task at hand: a point that is below
and/or to the right of the shaded regions on a plot like
Figure~\ref{fig:wpe_vs_mase_all} indicates that the time series has
more predictive structure than the forecast model can capture and
exploit---and that one would be well advised to try another method.

These curves were determined empirically using a specific error metric
and a finite set of forecast methods and time-series traces.  If one
uses a different error metric, the geometry of the heuristic will be
different---and may not even make sense, if one uses a metric that
does not support comparison across different time series.  And while
the methods and traces used in this study were chosen to be
representative of the practice, they are of course not completely
comprehensive.  It is certainly possible, for instance, that the
nonlinear dynamics of computer performance is subtly different from
the nonlinear dynamics of other systems.  Our preliminary results on
other systems (H\'enon, Lorenz, a random-walk process, SFI ``A'',
nonlinear transformations of the computer performance data) lead us to believe
that our results will generalize beyond the examples described in this
paper.  We are in the process of following up on that exploration with
a broader study of data, forecast methods, and error metrics.

% {\color{blue}agreed, I don't think it addds anything}\alert{I'm not
%   sure this paragraph adds anything.  Can/should we remove it?  Given
%   that information is a fundamental limitation in predictability, then
%   gathering and using more information is an obvious next step.  But
%   there is an equally obvious tension here between data length and
%   prediction speed: a forecast that requires half a second to compute
%   is not useful for the purposes of real-time control of a computer
%   system with a MHz clock rate, for instance.  Another alternative is
%   to sample several system variables simultaneously and build
%   multivariate models.  This is a particular challenge in nonlinear
%   LMA-type models, since multivariate delay-coordinate embedding
%   (e.g., \cite{cao-multivariate-embedding,deyle-sugihara2011}) can be
%   computationally prohibitive.  We are working on alternative methods
%   that sidestep that complexity.}
%

%Paragraphs on the issues that come up, including one about the "amount
%of info" one: if one could sample more variables, for instance, one
%might be able to do a better job of predicting more-complex traces.
%Segue to some handwaving about multivariable LMA models; tie this back
%to the "computers are NLD systems" stuff in the intro.  This is a real
%challenge; current approaches to this modelling problem have the major
%issue of taking way too long to build.  And that's a big issue if
%you're trying not just to classify, but to predict.  In a system that
%runs at MHz speeds, a prediction that takes milliseconds to compute is
%not useful.
%\end{it}

Nonstationarity is a serious challenge in any time-series modeling
problem.  Any regime shift that causes a change in the predictive
structure between the training signal and the test signal, for
instance, may skew the MASE score and thereby affecting the utility of
our heuristic.  Conversely, though, a MASE score of a random-walk
prediction that is significantly different from 1.0---as mentioned at
end of the previous section---could potentially be a good indicator of
nonstationarity.

Detecting regime shifts---and adapting prediction models
accordingly---is an important area of future work.  Indeed, one of the
first applications of permutation entropy was to recognize the regime
shift in brainwave data that occurs when someone has a
seizure~\cite{cao2004det}.  Recall that the signal in
Figure~\ref{fig:svd-ts-colored} was especially useful for the study in
this paper because it contained a number of different regimes.  We
segmented this signal visually, but one could imagine using some
combination of WPE and MASE to do so instead (e.g., in a sliding
window across the time series).  Automating regime-shift detection
would be an important step towards a fully adaptive modeling strategy,
where old models are discarded and new ones are rebuilt whenever the
time series enters a new regime.  Our WPE vs. MASE results could be
particularly powerful in this scenario, as their values could not only
help with regime-shift detection, but also suggest what kind of model
might work well in each new regime.  Of particular interest would be
the class of so-called \emph{hybrid systems}~\cite{hybrid}, which
exhibit discrete transitions between different continuous
regimes---e.g., a lathe that has an intermittent instability or
traffic at an internet router, whose characteristic normal traffic
patterns shift radically during an attack.  Effective modeling and
prediction of these kinds of systems is quite difficult; doing so
adaptively and automatically---in the manner that is alluded to at the
end of the previous paragraph---would be an interesting challenge.


