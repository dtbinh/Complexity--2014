\section{ Conclusions \& Future Work }\label{sec:conc}

Forecast strategies that are designed to capture predictive structure
are ineffective when signal complexity outweighs information
redundancy.  This poses a number of serious challenges in practice.
Without knowing anything about the generating process, it is difficult
to determine how much predictive structure is present in a noisy,
real-world time series.  And even if predictive structure exists, a
given forecast method may not work, simply because it cannot exploit
the structure that is present (e.g., a linear model of a nonlinear
process).  If a forecast model is not producing good results, a
practitioner needs to know why: is the reason that the data contain no
predictive structure---i.e., that no model will work---or is the model
that s/he is using simply not good enough?

In this paper, we have argued that redundancy~\cite{crutchfield2003}
is a useful definition of the inherent predictability of an empirical
time series.  To operationalize that definition, we use an
approximation of the Kolmogorov-Sinai entropy~\cite{lind95}, estimated
using a weighted version of the permutation entropy
of~\cite{bandt2002per}.  This WPE technique---an ordinal calculation
of forward information transfer in a time series---is ideal for our
purposes because it works with real-valued data and is known to
converge to the true entropy value. Using a variety of forecast models
and more than a hundred time-series data sets from a
computer-performance experiment, we have shown that prediction
accuracy is indeed correlated with weighted permutation entropy: the
higher the WPE, in general, the higher the prediction error.  The
relationship is roughly logarithmic.  [[This is just an observed result.
It makes sense because, firstly, any signal with zero entropy should
be perfectly predictable, and so should ideally have a MASE value of
zero.  As the entropy rises, the MASE value rise: slowly at first
because the signal still has lots of info, then more rapidly because
[[why]], and finally saturating at [[what]] because of [[why]].
Supporting our hypothesis, forecast errors for the \col and \svdfive
signals are higher than the corresponding WPEs suggest---except for
the nonlinear LMA predictor.  There are some exceptions: \svdone is
easier to predict than its WPE value suggests using any of the three
forecast strategies studied here.  On the whole, though, signals with
higher weighted permutation entropy are harder to predict.

% Further, the persistent WPE values of 0.5--0.6 for the {\tt
%   col\_major} trace are consistent with dynamical chaos, further
% corroborating the results of~\cite{mytkowicz09}.

An important practical corollary to this empirical correlation of
predictability and WPE is a practical strategy for assessing
appropriateness of forecast methods.  If the forecast produced by a
particular method is poor but the time series contains a significant
amount of predictive structure, one can reasonably conclude that that
method is inadequate to the task and that one should seek another
method.  The nonlinear LMA method, for instance, performs better in
most cases because it is more general.  (This is particularly apparent
in the \col and \svdfive examples.)
% , where the other two methods do not perform well.)
The \naive ~method, which simply predicts the mean, can work very well
on noisy signals because it effects a filtering operation.  The simple
random-walk strategy outperforms LMA, AutoARIMA, and the \naive
~method on the \gcc signal, which is extremely complex---i.e.,
extremely low redundancy.
%  \naive ~wins on \svdone with the exception to the 5 outliers.
The dashed curve and shaded region in
Figures~\ref{fig:wpe_vs_mase_best} and~\ref{fig:wpe_vs_mase_all}
operationalize the discussion in this paragraph.  These geometric
features are a preliminary, but potentially useful, empirical
guideline for knowing when a model is not well-matched to the task at
hand: [[a MASE score that is significantly higher than $3.58 \cdot
    \mathrm{WPE} - 1.91$, where $\mathrm{WPE}$ is that of the
    corresponding signal]] [[need to reword]], is an indication that
that time series has more predictive structure than that forecast
model can capture and exploit.

[[This paragraph duplicates material in the last paragraph of this
    section.  Some of it needs to be here rather than there, judging
    by the ref's reactions.  But the later paragraph has a nice
    concluding tone, so need to figure out what goes where.]]

This curve was determined empirically using a finite set of forecast
methods and data sets---the latter drawn from a single experimental
system.  Computer dynamics spans the full range of behavior reported
in the nonlinear dynamics literature.  Standard nonlinear time-series
analysis of data from these systems has confirmed the existence of
fixed points, periodic orbits of different periods, chaotic
trajectories with various Lyapunov exponents, etc. in their dynamics.
While it is certainly possible that the nonlinear dynamics of computer
performance is subtly different from the nonlinear dynamics of other
systems---in a manner that cannot be detected by traditional nonlinear
time-series analysis---we believe that our results will hold for time
series drawn from other physical systems.  We are certainly aware that
this claim may not be true, however, and we are in the process of a
follow-up study exploring a broader range of applications.
Preliminary results of this study show that MASE vs. WPE points for
data from the SFI prediction competition \cite{weigend-book} fall in the shaded
region on Figure [[what]]\footnote{Synthetic data from paradigmatic
  systems like the H\'{e}non map \cite{henon} and the Lorenz system
  \cite{lorenz63} also fit this pattern.}.

Given that information is a fundamental limitation in predictability,
then gathering and using more information is an obvious next step.
But there is an equally obvious tension here between data length and
prediction speed: a forecast that requires half a second to compute is
not useful for the purposes of real-time control of a computer system
with a MHz clock rate, for instance.  Another alternative is to sample
several system variables simultaneously and build multivariate models.
This is a particular challenge in nonlinear LMA-type models, since
multivariate delay-coordinate embedding (e.g.,
\cite{cao-multivariate-embedding,deyle-sugihara2011}) can be
computationally prohibitive.  We are working on alternative methods
that sidestep that complexity.

%Paragraphs on the issues that come up, including one about the "amount
%of info" one: if one could sample more variables, for instance, one
%might be able to do a better job of predicting more-complex traces.
%Segue to some handwaving about multivariable LMA models; tie this back
%to the "computers are NLD systems" stuff in the intro.  This is a real
%challenge; current approaches to this modelling problem have the major
%issue of taking way too long to build.  And that's a big issue if
%you're trying not just to classify, but to predict.  In a system that
%runs at MHz speeds, a prediction that takes milliseconds to compute is
%not useful.
%\end{it}

Nonstationarity is a serious challenge in any time-series modeling
problem.  Indeed, one of the first applications of permutation entropy
was to recognize the regime shift in brainwave data that occurs when
someone has a seizure~\cite{cao2004det}.  Recall that the signal in
Figure~\ref{fig:svd-ts-colored} was especially useful for the study in
this paper because it contained a number of different regimes.  We
segmented this signal visually, but one could imagine using
permutation entropy to do so instead.  Automating regime-shift
detection would be an important step towards a fully adaptive modeling
strategy, where old models are discarded and new ones are rebuilt
whenever the time series enters a new regime.  WPE would be
particularly powerful in this scenario, as its value can not only help
with regime-shift detection, but also suggest what kind of model might
work well in each new regime.

All of the experiments described in this paper involve a particular
physical system.  We chose that system because its behavior spans a
broad spectrum of classical time series patterns.  Since these
patterns (dynamical chaos, periodicities, noise, etc.) are generic, we
believe that our results will generalize beyond this particular
system.  Testing that claim with different examples is another
important next step---and one that will be critical to validating our
claims about the utility of the shaded region around the dashed curve
in Figure [[what]] as a heuristic for determining whether a particular
forecast method is well-matched to a particular task.  Of particular
interest would be the class of so-called \emph{hybrid
  systems}~\cite{hybrid}, which exhibit discrete transitions between
different continuous regimes---e.g., a lathe that has an intermittent
instability or traffic at an internet router, whose characteristic
normal traffic patterns shift radically during an attack.  Effective
modeling and prediction of these kinds of systems is quite difficult;
doing so adaptively and automatically---in the manner that is alluded
to at the end of the previous paragraph---would be an even more
important challenge.

% The way structure, information and complexity are processed by a
% generating process play a crucial role in the success of a given
% prediction scheme.
